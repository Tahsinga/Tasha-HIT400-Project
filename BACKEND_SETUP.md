# Tasha Bot â€” Backend Architecture Setup

## What Changed

Your app now uses a **secure backend architecture**:

- âœ… **OpenAI API key on backend only** (not in Flutter app)
- âœ… **Backend handles chunking, batching, and retries**
- âœ… **App communicates via secure HTTP + app-level auth**
- âœ… **Better performance & reliability**

## Quick Start

### 1. Backend Setup (Python)

```bash
cd backend/
pip install -r requirements.txt
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
python -m uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Backend runs at: `http://localhost:8000`

### 2. Flutter App Configuration

Open the app's Settings screen and enter:

- **Backend URL**: `http://localhost:8000` (or your server URL)
- **App Auth Token**: `your-app-secret-token-here` (can be anything for local dev)

The app will save these in `SharedPreferences` and use them for all API calls.

### 3. Test the connection

- Open the app and navigate to Chat (RAG) page
- Try asking a question â€” the app will use your backend!
- Check the Python backend logs for `[RagService]` and `[EmbeddingService]` messages

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flutter App (Dart)    â”‚
â”‚  - UI                   â”‚
â”‚  - Chunking             â”‚
â”‚  - Local VectorDB       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ HTTP + Bearer Token
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python FastAPI Backend â”‚
â”‚  - OpenAI API Key       â”‚
â”‚  - Rate Limiting        â”‚
â”‚  - Batch Processing     â”‚
â”‚  - Response Streaming   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ OPENAI_API_KEY (env var)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI API            â”‚
â”‚  - GPT-4o-mini          â”‚
â”‚  - Embeddings           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Files

### Backend

- `backend/main.py` â€” FastAPI server with all endpoints
- `backend/requirements.txt` â€” Python dependencies
- `backend/.env` â€” Environment variables (add your OpenAI key here)

### Flutter

- `lib/services/backend_client.dart` â€” HTTP client for backend
- `lib/services/embedding_service.dart` â€” Uses backend embeddings
- `lib/services/rag_service.dart` â€” Uses backend RAG endpoint
- `lib/services/backend_config.dart` â€” Configuration manager

## Backend Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/health` | GET | Health check |
| `/process_chunk` | POST | Process single chunk with OpenAI |
| `/embeddings` | POST | Get embeddings for texts |
| `/rag/answer` | POST | Answer question using chunks (RAG) |
| `/train/book` | POST | Generate Q/A pairs for training |

## Environment Variables

**Backend (.env):**
```
OPENAI_API_KEY=sk-your-real-openai-key
```

**Flutter (Settings screen):**
```
Backend URL: http://localhost:8000 (or your production URL)
App Auth Token: your-app-secret-token
```

## Security Best Practices

âœ… **Never put OpenAI key in the app** â€” it's on the backend only
âœ… **Use app-level auth tokens** â€” validate requests on backend
âœ… **Rate limiting** â€” enforce limits per user/minute
âœ… **Logging** â€” audit all API calls
âœ… **HTTPS** â€” use in production (set `https://` URL)
âœ… **Environment variables** â€” never commit secrets

## Troubleshooting

### "Connection refused" / "Backend not found"
- Make sure Python backend is running: `python -m uvicorn main:app --reload`
- Check backend URL in Settings matches where it's running (default: `http://localhost:8000`)

### "Unauthorized" error
- Make sure App Auth Token matches in both Settings and backend (or in `.env` if deploying)
- Update backend `.env` with a real app token if needed

### "Rate limit exceeded"
- Wait 1 minute before retrying
- Adjust `REQUESTS_PER_MINUTE` and `REQUESTS_PER_HOUR` in `main.py` if needed

### "OpenAI timeout"
- Your text chunks are too large or OpenAI is slow
- Try smaller chunks (< 2000 chars each)
- Retry with fewer chunks

### Backend errors in logs
- Check Python backend logs for `[ERROR]` messages
- Ensure `OPENAI_API_KEY` is set correctly in `.env`
- Make sure `requirements.txt` packages are installed

## Next Steps

1. âœ… **Run backend locally** to test
2. âœ… **Configure Flutter app** with backend URL/token
3. âœ… **Test chat** and verify no UI freezes
4. ğŸ“¦ **Deploy backend** (Railway, Render, AWS Lambda, etc.)
5. ğŸ”’ **Enable HTTPS** and proper auth for production
6. ğŸ“Š **Monitor** API calls and costs

## Performance Gains

With this architecture:
- âœ… **No UI freezes** â€” heavy OpenAI calls happen on backend
- âœ… **Better answers** â€” backend can batch/optimize requests
- âœ… **Cheaper** â€” backend can combine requests, cache responses
- âœ… **Safer** â€” no API keys in reverse-engineered app
- âœ… **Scalable** â€” backend can handle rate limits, retries

## Questions?

Check the backend `README.md` for more details or the logs for debugging.

Happy coding! ğŸš€
